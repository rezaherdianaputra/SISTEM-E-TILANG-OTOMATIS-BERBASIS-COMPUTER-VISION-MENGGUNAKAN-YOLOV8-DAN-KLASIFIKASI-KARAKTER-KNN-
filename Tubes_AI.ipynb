{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Install Library & Download Dataset YOLO\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"TjWK841PaXoG3k7fu8P7\")\n",
        "project = rf.workspace(\"ranias-workspace\").project(\"dataset-plat-nomor\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nâœ… Dataset terdownload di folder: {dataset.location}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "0k_mKnGkhDeE",
        "outputId": "48652e4e-df36-401e-faf6-34f11e244db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Dataset-plat-nomor-5 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122962/122962 [00:08<00:00, 14929.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Dataset-plat-nomor-5 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3760/3760 [00:00<00:00, 6192.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Dataset terdownload di folder: /content/Dataset-plat-nomor-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Training YOLOv8\n",
        "import os\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Cek apakah dataset sudah terdownload\n",
        "if not 'dataset' in locals() and not os.path.exists(\"dataset-plat-nomor-5\"):\n",
        "    print(\"âš ï¸ Dataset belum terdeteksi. Pastikan Langkah 1 sudah dijalankan!\")\n",
        "else:\n",
        "    print(\"âœ… Library YOLO siap. Memulai konfigurasi...\")\n",
        "    model_yolo = YOLO('yolov8n.pt')\n",
        "\n",
        "    # Cari file data.yaml otomatis\n",
        "    data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "    print(f\"ğŸ“‚ Menggunakan konfigurasi data dari: {data_yaml_path}\")\n",
        "\n",
        "    results = model_yolo.train(data=data_yaml_path, epochs=50, imgsz=640)\n",
        "\n",
        "    print(\"âœ… Training Selesai! Model siap digunakan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bU5-WYcwhJpS",
        "outputId": "a5e0c31a-58ce-499f-b26f-c218c751ba7e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.243-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.243-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.243 ultralytics-thop-2.0.18\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "âœ… Library YOLO siap. Memulai konfigurasi...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 272.2MB/s 0.0s\n",
            "ğŸ“‚ Menggunakan konfigurasi data dari: /content/Dataset-plat-nomor-5/data.yaml\n",
            "Ultralytics 8.3.243 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Dataset-plat-nomor-5/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 91.8MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    754042  ultralytics.nn.modules.head.Detect           [14, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,013,578 parameters, 3,013,562 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 277.4MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 713.8Â±664.3 MB/s, size: 42.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset-plat-nomor-5/train/labels... 1203 images, 1 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1203/1203 1.9Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset-plat-nomor-5/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 336, len(boxes) = 1321. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 372.4Â±125.3 MB/s, size: 32.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset-plat-nomor-5/valid/labels... 448 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 448/448 929.7it/s 0.5s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset-plat-nomor-5/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 88, len(boxes) = 487. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000556, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.15G     0.8102      2.367      1.149         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.0it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.5it/s 5.5s\n",
            "                   all        448        487      0.971     0.0486     0.0565     0.0429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.66G     0.7005      1.028      1.038          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.8it/s 5.1s\n",
            "                   all        448        487      0.974     0.0692     0.0901     0.0597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.67G     0.7138      0.929      1.043         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.0it/s 4.6s\n",
            "                   all        448        487      0.973     0.0698     0.0692     0.0452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.69G     0.6832     0.8358      1.037          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.1it/s 4.6s\n",
            "                   all        448        487      0.975     0.0738     0.0784     0.0585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.71G     0.6704     0.7538      1.022          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.1it/s 4.5s\n",
            "                   all        448        487      0.897     0.0724      0.087     0.0669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.72G     0.6795      0.699      1.022         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.0s\n",
            "                   all        448        487       0.36     0.0735     0.0581     0.0466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.74G       0.65      0.652      1.017          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.1s\n",
            "                   all        448        487      0.206     0.0729     0.0581     0.0471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.76G     0.6431      0.605      1.004         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.6it/s 3.9s\n",
            "                   all        448        487      0.283     0.0744     0.0536     0.0429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.78G     0.6417     0.5724      1.011          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.206     0.0734     0.0541     0.0437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.79G     0.6392     0.5491     0.9945          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.6it/s 3.9s\n",
            "                   all        448        487      0.206      0.074     0.0586     0.0472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.81G     0.6302      0.522     0.9997          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.206     0.0744     0.0585      0.046\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.83G      0.641     0.5291      1.003         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.129     0.0744     0.0547     0.0439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.85G     0.6417     0.4957      1.008         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.0s\n",
            "                   all        448        487      0.206     0.0744     0.0603     0.0504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.86G     0.6091     0.4722     0.9923          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.1it/s 4.5s\n",
            "                   all        448        487      0.206     0.0749     0.0574     0.0464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.88G     0.6092     0.4636     0.9878         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.128      0.074     0.0532     0.0431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50       2.9G     0.6089     0.4565     0.9873         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.129     0.0744     0.0576     0.0464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.91G     0.5736     0.4235     0.9746          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.4s\n",
            "                   all        448        487       0.13     0.0749     0.0561     0.0456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.93G     0.5859     0.4258     0.9821         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.2s\n",
            "                   all        448        487      0.129     0.0742     0.0596     0.0472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.95G     0.5945     0.4234       0.98          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.6it/s 3.9s\n",
            "                   all        448        487      0.129     0.0744     0.0618     0.0513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.96G     0.5909     0.4164     0.9803          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.0s\n",
            "                   all        448        487      0.129      0.074     0.0533     0.0429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.98G     0.5779     0.4049     0.9787         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.129     0.0742     0.0601     0.0498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50         3G     0.5878     0.4091     0.9807          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.129     0.0748     0.0631     0.0523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      3.02G      0.572     0.3932     0.9775          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.1it/s 4.5s\n",
            "                   all        448        487       0.13     0.0738     0.0629     0.0523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      3.03G     0.5848     0.3935     0.9779         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.7it/s 3.8s\n",
            "                   all        448        487      0.129     0.0746      0.055     0.0453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      3.05G     0.5813     0.3813     0.9782          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.4it/s 4.1s\n",
            "                   all        448        487      0.129     0.0744     0.0623     0.0523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      3.07G     0.5679     0.3745     0.9661         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.0s\n",
            "                   all        448        487      0.129     0.0752     0.0599     0.0491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      3.08G     0.5591     0.3739     0.9752         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.2s\n",
            "                   all        448        487      0.129     0.0749     0.0537     0.0434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50       3.1G     0.5576     0.3679      0.961          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487       0.13     0.0751     0.0565     0.0457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      3.12G     0.5412     0.3543     0.9551          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.3s\n",
            "                   all        448        487      0.129     0.0751     0.0616     0.0518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      3.14G     0.5413     0.3545     0.9588          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.7it/s 3.8s\n",
            "                   all        448        487      0.129     0.0751      0.056     0.0456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      3.15G     0.5398     0.3511     0.9631         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.6it/s 3.8s\n",
            "                   all        448        487      0.129      0.075      0.062     0.0524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      3.17G     0.5416     0.3471     0.9515          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.2s\n",
            "                   all        448        487      0.129     0.0753     0.0607     0.0505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.19G     0.5165     0.3408     0.9571          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.2s\n",
            "                   all        448        487       0.13     0.0751     0.0587     0.0482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50       3.2G     0.5287     0.3362     0.9516         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.129     0.0751     0.0604      0.051\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      3.22G     0.5216     0.3339     0.9571         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.3it/s 22.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.4it/s 4.1s\n",
            "                   all        448        487       0.13     0.0751     0.0626     0.0526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      3.24G     0.5218     0.3358     0.9613          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.5it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.1it/s 4.5s\n",
            "                   all        448        487      0.129      0.074     0.0557     0.0463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      3.26G     0.5205     0.3293      0.959          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.4it/s 4.2s\n",
            "                   all        448        487      0.129     0.0744     0.0573     0.0475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      3.27G     0.5324     0.3387     0.9588         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 3.9s\n",
            "                   all        448        487      0.129     0.0749     0.0613     0.0516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.29G     0.5012     0.3144     0.9497          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.4s\n",
            "                   all        448        487      0.129     0.0746     0.0628     0.0531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.31G     0.5226     0.3236     0.9516         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.4it/s 22.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.5it/s 4.0s\n",
            "                   all        448        487      0.129     0.0743     0.0601     0.0502\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.32G     0.5396     0.3787     0.9463          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.1it/s 24.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.6it/s 3.9s\n",
            "                   all        448        487      0.129     0.0746     0.0569      0.047\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      3.34G     0.5279     0.3455     0.9316          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487      0.206     0.0746     0.0626     0.0527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.36G     0.5068     0.3289      0.925          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.4it/s 4.1s\n",
            "                   all        448        487       0.13     0.0749     0.0633     0.0527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.37G     0.5194     0.3265     0.9394          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.6it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.2it/s 4.3s\n",
            "                   all        448        487       0.13     0.0737     0.0626     0.0519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      3.39G     0.5095     0.3118     0.9229          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.7it/s 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.9it/s 4.8s\n",
            "                   all        448        487       0.13     0.0744      0.063     0.0529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      3.41G     0.4968     0.3075     0.9302          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.7it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.0it/s 4.7s\n",
            "                   all        448        487       0.13     0.0737      0.064     0.0541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      3.43G     0.4917     0.3031     0.9223          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.8it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.6it/s 5.3s\n",
            "                   all        448        487      0.129     0.0749     0.0637     0.0537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      3.44G     0.4913     0.2982     0.9297          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.8it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.6it/s 5.3s\n",
            "                   all        448        487       0.13     0.0742     0.0641      0.054\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      3.46G     0.4848     0.2992     0.9228          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.7it/s 20.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.7it/s 5.1s\n",
            "                   all        448        487       0.13     0.0744     0.0637     0.0536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      3.48G     0.4813     0.2942     0.9205          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 76/76 3.8it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 2.7it/s 5.1s\n",
            "                   all        448        487       0.13      0.074      0.064     0.0538\n",
            "\n",
            "50 epochs completed in 0.367 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.243 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,008,378 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 3.3it/s 4.3s\n",
            "                   all        448        487      0.897     0.0723      0.087     0.0669\n",
            "                     0          5          5          1          0          0          0\n",
            "                Bangku          1          1          1          0          0          0\n",
            "                 Human          2          3          1          0          0          0\n",
            "               Jakarta          1          1          1          0          0          0\n",
            "                 Mobil          1          1          1          0          0          0\n",
            "                 Motor          1          1          1          0          0          0\n",
            "        Pekanbaru Riau          2          2          1          0          0          0\n",
            "        Plat Kendaraan          3          3          1          0          0          0\n",
            "                Tangan          1          1          1          0          0          0\n",
            "                  plat          2          2          1          0     0.0105     0.0072\n",
            "            plat-nomor        309        337      0.658       0.94      0.787      0.625\n",
            "             platNomor        107        107          1          0      0.335      0.237\n",
            "                 plate         22         23          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "âœ… Training Selesai! Model siap digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Siapkan Dataset Huruf\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "PATH_FOLDER_DRIVE = '/content/drive/MyDrive/Dataset_Plat'\n",
        "DATASET_KNN_PATH = '/content/dataset_huruf'\n",
        "\n",
        "if not os.path.exists(DATASET_KNN_PATH):\n",
        "    print(f\"ğŸš€ Sedang menyalin data dari Drive: {PATH_FOLDER_DRIVE}\")\n",
        "    print(\"â³ Mohon bersabar, menyalin ribuan file folder biasa agak lama...\")\n",
        "\n",
        "    try:\n",
        "        # Menyalin seluruh isi folder\n",
        "        shutil.copytree(PATH_FOLDER_DRIVE, DATASET_KNN_PATH)\n",
        "        print(f\"âœ… SUKSES! Dataset tersalin ke: {DATASET_KNN_PATH}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ ERROR: Folder tidak ditemukan! Cek lagi nama folder di variabel PATH_FOLDER_DRIVE.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error lain: {e}\")\n",
        "else:\n",
        "    print(\"âœ… Dataset sudah siap di Local Colab.\")"
      ],
      "metadata": {
        "id": "ErnoUU32WC7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544f6a4b-ea33-44d7-8c4f-793f56d70503",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ğŸš€ Sedang menyalin data dari Drive: /content/drive/MyDrive/Dataset_Plat\n",
            "â³ Mohon bersabar, menyalin ribuan file folder biasa agak lama...\n",
            "âœ… SUKSES! Dataset tersalin ke: /content/dataset_huruf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Fungsi Deteksi & Segmentasi\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load Model YOLO\n",
        "best_model_path = '/content/runs/detect/train/weights/best.pt'\n",
        "if os.path.exists(best_model_path):\n",
        "    yolo_plate_model = YOLO(best_model_path)\n",
        "else:\n",
        "    print(\"âš ï¸ Model YOLO tidak ditemukan! Pastikan sudah training (Cell 2) atau Load dari Drive.\")\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Hanya untuk mencari kontur/lokasi huruf (Bukan untuk diambil gambarnya)\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 19, 5)\n",
        "\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    # Closing untuk menyatukan bagian huruf yang terpisah\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return binary\n",
        "\n",
        "def normalize_character(char_img, size=(20, 30)):\n",
        "    return cv2.resize(char_img, size)\n",
        "\n",
        "def locate_plate_yolo(image):\n",
        "    results = yolo_plate_model(image, verbose=False)\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        if len(boxes) > 0:\n",
        "            box = boxes[0]\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "            cropped = image[y1:y2, x1:x2]\n",
        "            return cropped\n",
        "    return None\n",
        "\n",
        "def segment_characters(binary_img, plate_img_gray):\n",
        "    \"\"\"\n",
        "    Update: Memotong huruf dari gambar GRAYSCALE (Plate Asli),\n",
        "    bukan dari binary yang kotor.\n",
        "    \"\"\"\n",
        "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    chars = []\n",
        "\n",
        "    # Urutkan dari kiri ke kanan\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in contours]\n",
        "    if len(contours) > 0:\n",
        "        (contours, boundingBoxes) = zip(*sorted(zip(contours, boundingBoxes), key=lambda b: b[1][0]))\n",
        "\n",
        "    h_plat, w_plat = binary_img.shape\n",
        "\n",
        "    potential_chars = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        aspect_ratio = w / h\n",
        "        area = w * h\n",
        "\n",
        "        # Filter Ukuran\n",
        "        if h > h_plat * 0.35 and h < h_plat * 0.95 and area > 100 and 0.15 < aspect_ratio < 1.0:\n",
        "             potential_chars.append((x, y, w, h))\n",
        "\n",
        "    # Y-Alignment & Crop Raw\n",
        "    if len(potential_chars) > 0:\n",
        "        y_positions = [item[1] for item in potential_chars]\n",
        "        median_y = np.median(y_positions)\n",
        "        y_tolerance = h_plat * 0.2\n",
        "\n",
        "        # Urut X axis\n",
        "        potential_chars = sorted(potential_chars, key=lambda item: item[0])\n",
        "\n",
        "        for (x, y, w, h) in potential_chars:\n",
        "            if abs(y - median_y) < y_tolerance:\n",
        "                roi_gray = plate_img_gray[y:y+h, x:x+w]\n",
        "                roi_gray = cv2.copyMakeBorder(roi_gray, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=0)\n",
        "                chars.append(roi_gray)\n",
        "\n",
        "    return chars"
      ],
      "metadata": {
        "id": "WIAL0JasWDwH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5: Setup & Training Otak\n",
        "from skimage.feature import hog\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# --- 1. SETUP YOLO (PENCARI PLAT) ---\n",
        "# Load model YOLO yang sudah ada (dari training sebelumnya)\n",
        "best_model_path = '/content/runs/detect/train/weights/best.pt'\n",
        "if os.path.exists(best_model_path):\n",
        "    yolo_plate_model = YOLO(best_model_path)\n",
        "    print(\"âœ… Model YOLO (Pencari Plat) Berhasil Dimuat!\")\n",
        "else:\n",
        "    print(\"âš ï¸ Model YOLO belum training! Gunakan yolov8n.pt standar (kurang akurat).\")\n",
        "    yolo_plate_model = YOLO('yolov8n.pt')\n",
        "\n",
        "def locate_plate_yolo(image):\n",
        "    results = yolo_plate_model(image, verbose=False)\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        if len(boxes) > 0:\n",
        "            box = boxes[0]\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "            cropped = image[y1:y2, x1:x2]\n",
        "            return cropped\n",
        "    return None\n",
        "\n",
        "def preprocess_image(image):\n",
        "    if len(image.shape) == 3: gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else: gray = image\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 19, 5)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "    return binary\n",
        "\n",
        "# --- 2. FUNGSI HOG HD (MATA DEWA) ---\n",
        "def extract_hog_features_hd(image):\n",
        "    # Resize HD (40x64)\n",
        "    target_size = (40, 64)\n",
        "    resized = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Adaptive Threshold (Menjaga topi angka 7)\n",
        "    binary = cv2.adaptiveThreshold(resized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 13, 5)\n",
        "\n",
        "    # Dilation Tipis (Menyambung garis putus)\n",
        "    kernel = np.ones((2,2), np.uint8)\n",
        "    binary = cv2.dilate(binary, kernel, iterations=1)\n",
        "\n",
        "    # Ekstrak HOG\n",
        "    fd, _ = hog(binary, orientations=9, pixels_per_cell=(8, 8),\n",
        "                cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    return fd, binary\n",
        "\n",
        "# --- 3. FUNGSI POTONG HURUF ---\n",
        "def segment_characters_hd(binary_img, plate_img_gray):\n",
        "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    chars = []\n",
        "    h_plat, w_plat = binary_img.shape\n",
        "    potential_chars = []\n",
        "\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        aspect = w / h\n",
        "        area = w * h\n",
        "        if h > h_plat*0.35 and h < h_plat*0.95 and area > 100 and 0.15 < aspect < 1.0:\n",
        "            potential_chars.append((x, y, w, h))\n",
        "\n",
        "    if potential_chars:\n",
        "        potential_chars.sort(key=lambda x: x[0])\n",
        "        ys = [c[1] for c in potential_chars]\n",
        "        median_y = np.median(ys)\n",
        "        for (x, y, w, h) in potential_chars:\n",
        "            if abs(y - median_y) < h_plat * 0.2:\n",
        "                roi_gray = plate_img_gray[y:y+h, x:x+w]\n",
        "                # Padding 3px\n",
        "                roi_gray = cv2.copyMakeBorder(roi_gray, 3, 3, 3, 3, cv2.BORDER_CONSTANT, value=0)\n",
        "                chars.append(roi_gray)\n",
        "    return chars\n",
        "\n",
        "# --- 4. TRAINING KNN (PROSES LAMA DI SINI) ---\n",
        "def train_knn_hd(path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    if not os.path.exists(path):\n",
        "        print(\"âŒ Dataset huruf tidak ditemukan! Cek folder dataset.\")\n",
        "        return None\n",
        "\n",
        "    print(\"ğŸš€ Sedang Training HOG Resolusi Tinggi (Tunggu sebentar)...\")\n",
        "    for folder in sorted(os.listdir(path)):\n",
        "        folder_path = os.path.join(path, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path)[:300]:\n",
        "                try:\n",
        "                    img = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        features, _ = extract_hog_features_hd(img)\n",
        "                        data.append(features)\n",
        "                        labels.append(folder)\n",
        "                except: continue\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=3, metric='manhattan')\n",
        "    knn.fit(data, labels)\n",
        "    print(\"âœ… TRAIN SELESAI! Model KNN siap digunakan di Cell bawah.\")\n",
        "    return knn\n",
        "\n",
        "# Eksekusi Training\n",
        "DATASET_KNN_PATH = '/content/dataset_huruf'\n",
        "knn_final_hd = train_knn_hd(DATASET_KNN_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "AUObIBBDvXZz",
        "outputId": "99a2cf5f-80d3-4d02-8797-29062f39361d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model YOLO (Pencari Plat) Berhasil Dimuat!\n",
            "ğŸš€ Sedang Training HOG Resolusi Tinggi (Tunggu sebentar)...\n",
            "âœ… TRAIN SELESAI! Model KNN siap digunakan di Cell bawah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6: Testing Foto\n",
        "from google.colab import files\n",
        "\n",
        "# Cek apakah model sudah siap\n",
        "if 'knn_final_hd' not in globals() or knn_final_hd is None:\n",
        "    print(\"âš ï¸ HARAP RUN CELL 1 DULU SAMPAI SELESAI!\")\n",
        "else:\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print(f\"\\nğŸš˜ SEDANG MEMPROSES: {fn}\")\n",
        "        img = cv2.imread(fn)\n",
        "\n",
        "        # 1. YOLO (Cari Plat)\n",
        "        plate_img = locate_plate_yolo(img)\n",
        "        if plate_img is None:\n",
        "            print(\"âŒ Plat tidak ditemukan YOLO.\")\n",
        "            continue\n",
        "\n",
        "        # 2. Potong Huruf\n",
        "        if len(plate_img.shape) == 3: plate_gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
        "        else: plate_gray = plate_img\n",
        "\n",
        "        guide = preprocess_image(plate_img)\n",
        "        chars = segment_characters_hd(guide, plate_gray)\n",
        "\n",
        "        # Tampilkan Plat\n",
        "        plt.figure(figsize=(5,2))\n",
        "        plt.imshow(cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off'); plt.show()\n",
        "\n",
        "        # 3. Baca Huruf pakai Model dari Cell 1\n",
        "        res_text = \"\"\n",
        "        if chars:\n",
        "            fig, axes = plt.subplots(1, len(chars), figsize=(12, 2))\n",
        "            if len(chars)==1: axes=[axes]\n",
        "\n",
        "            for i, char in enumerate(chars):\n",
        "                # Ekstrak fitur input\n",
        "                features_input, bin_view = extract_hog_features_hd(char)\n",
        "\n",
        "                # Prediksi\n",
        "                pred = knn_final_hd.predict([features_input])[0]\n",
        "                res_text += pred\n",
        "\n",
        "                # Tampilkan\n",
        "                axes[i].imshow(bin_view, cmap='gray')\n",
        "                axes[i].set_title(pred, color='green', fontweight='bold', fontsize=16)\n",
        "                axes[i].axis('off')\n",
        "            plt.show()\n",
        "            print(f\"ğŸ“ HASIL BACAAN: {res_text}\")\n",
        "        else:\n",
        "            print(\"âŒ Huruf tidak terdeteksi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "collapsed": true,
        "id": "Scc7MjehvXp9",
        "outputId": "7837bae0-030c-4dd9-d54b-02a59437fc6b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f778117-693b-4186-88e1-037ad46a2d3e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f778117-693b-4186-88e1-037ad46a2d3e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Batch Processing + F1-Score\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# --- KONFIGURASI FOLDER ---\n",
        "FOLDER_TEST = '/content/foto_test'\n",
        "\n",
        "# 1. Cek dulu apakah Cell 1 udah dijalankan?\n",
        "# Kita cek apakah fungsi 'locate_plate_yolo' dan model 'knn_final_hd' sudah ada di memori\n",
        "if 'locate_plate_yolo' not in globals() or 'knn_final_hd' not in globals():\n",
        "    print(\"âš ï¸ ERROR: Harap RUN CELL 1 dulu sampai selesai!\")\n",
        "    print(\"ğŸ‘‰ Kita butuh fungsi 'locate_plate_yolo' dan model 'knn_final_hd' dari sana.\")\n",
        "else:\n",
        "    # 2. Cek Folder Foto\n",
        "    if not os.path.exists(FOLDER_TEST):\n",
        "        os.makedirs(FOLDER_TEST)\n",
        "        print(f\"ğŸ“‚ Folder '{FOLDER_TEST}' dibuat. Masukkan foto dulu!\")\n",
        "    else:\n",
        "        files_test = sorted([f for f in os.listdir(FOLDER_TEST) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "        if len(files_test) == 0:\n",
        "            print(f\"âš ï¸ Folder '{FOLDER_TEST}' KOSONG! Upload foto dulu.\")\n",
        "        else:\n",
        "            print(f\"ğŸš€ Memproses {len(files_test)} foto... (Menghitung F1-Score)\")\n",
        "\n",
        "            rekap_hasil = []\n",
        "\n",
        "            # --- VARIABEL HITUNG SCORE ---\n",
        "            tp = 0 # Benar (True Positive)\n",
        "            fp = 0 # Salah Baca (False Positive)\n",
        "            fn = 0 # Gagal Deteksi (False Negative)\n",
        "\n",
        "            for fn_name in files_test:\n",
        "                path_img = os.path.join(FOLDER_TEST, fn_name)\n",
        "                # Kunci Jawaban (Nama File)\n",
        "                nama_asli = os.path.splitext(fn_name)[0].replace(\" \", \"\").upper()\n",
        "\n",
        "                img = cv2.imread(path_img)\n",
        "                if img is None: continue\n",
        "\n",
        "                # --- 1. DETEKSI PLAT (Pake Fungsi Lama yg Terbukti Jalan) ---\n",
        "                plate_img = locate_plate_yolo(img)\n",
        "\n",
        "                pred_text = \"\"\n",
        "                status_detail = \"\"\n",
        "\n",
        "                if plate_img is None:\n",
        "                    # Gagal Deteksi Plat\n",
        "                    fn += 1\n",
        "                    status_detail = \"âŒ FN (Gagal Deteksi)\"\n",
        "                    pred_text = \"-\"\n",
        "                else:\n",
        "                    # --- 2. BACA HURUF (KNN) ---\n",
        "                    # Proses Preprocessing & Segmentasi\n",
        "                    if len(plate_img.shape) == 3: plate_gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
        "                    else: plate_gray = plate_img\n",
        "\n",
        "                    guide = preprocess_image(plate_img)\n",
        "                    chars = segment_characters_hd(guide, plate_gray)\n",
        "\n",
        "                    if chars:\n",
        "                        for char in chars:\n",
        "                            features_input, _ = extract_hog_features_hd(char)\n",
        "                            pred = knn_final_hd.predict([features_input])[0]\n",
        "                            pred_text += pred\n",
        "                    else:\n",
        "                        pred_text = \"GAGALCROP\"\n",
        "\n",
        "                    # --- 3. CEK BENAR/SALAH ---\n",
        "                    clean_pred = pred_text.replace(\" \", \"\").upper()\n",
        "\n",
        "                    if clean_pred == \"GAGALCROP\" or clean_pred == \"\":\n",
        "                        fn += 1 # Anggap False Negative kalau gagal crop huruf\n",
        "                        status_detail = \"FN (Gagal Crop)\"\n",
        "                    elif clean_pred == nama_asli:\n",
        "                        tp += 1 # Benar Sempurna\n",
        "                        status_detail = \"TP (Benar)\"\n",
        "                    else:\n",
        "                        fp += 1 # Salah Baca\n",
        "                        status_detail = \"FP (Salah Baca)\"\n",
        "\n",
        "                # Masukkan ke list\n",
        "                rekap_hasil.append({\n",
        "                    \"Nama File\": fn_name,\n",
        "                    \"Kunci Jawaban\": nama_asli,\n",
        "                    \"Prediksi AI\": pred_text,\n",
        "                    \"Status\": status_detail\n",
        "                })\n",
        "\n",
        "            # --- TAMPILKAN TABEL ---\n",
        "            if rekap_hasil:\n",
        "                df = pd.DataFrame(rekap_hasil)\n",
        "                print(\"\\n\" + \"=\"*50)\n",
        "                print(\"ğŸ“Š TABEL HASIL DETEKSI\")\n",
        "                print(\"=\"*50)\n",
        "                display(df)\n",
        "\n",
        "                # --- HITUNG F1-SCORE ---\n",
        "                total_data = tp + fp + fn\n",
        "\n",
        "                # Rumus (Pake if biar gak error bagi nol)\n",
        "                presisi = (tp / (tp + fp)) * 100 if (tp + fp) > 0 else 0\n",
        "                recall  = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
        "                akurasi = (tp / total_data) * 100 if total_data > 0 else 0\n",
        "\n",
        "                if (presisi + recall) > 0:\n",
        "                    f1_score = 2 * (presisi * recall) / (presisi + recall)\n",
        "                else:\n",
        "                    f1_score = 0\n",
        "\n",
        "                print(\"\\n\" + \"=\"*50)\n",
        "                print(\"ğŸ“ˆ LAPORAN EVALUASI MODEL (F1-SCORE)\")\n",
        "                print(\"=\"*50)\n",
        "                print(f\"Total Data      : {total_data}\")\n",
        "                print(f\"âœ… True Positive : {tp} (Benar)\")\n",
        "                print(f\"âš ï¸ False Positive: {fp} (Salah Baca)\")\n",
        "                print(f\"âŒ False Negative: {fn} (Gagal Deteksi)\")\n",
        "                print(\"-\" * 30)\n",
        "                print(f\"ğŸ¯ AKURASI   : {akurasi:.2f}%\")\n",
        "                print(f\"ğŸ¯ PRESISI   : {presisi:.2f}%\")\n",
        "                print(f\"ğŸ¯ RECALL    : {recall:.2f}%\")\n",
        "                print(f\"ğŸ† F1-SCORE  : {f1_score:.2f}%\")\n",
        "                print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1556
        },
        "collapsed": true,
        "id": "QJPU8c6oEbsL",
        "outputId": "fcc76f8e-b706-45c0-c6bb-33941106e77c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Memproses 50 foto... (Menghitung F1-Score)\n",
            "\n",
            "==================================================\n",
            "ğŸ“Š TABEL HASIL DETEKSI\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Nama File Kunci Jawaban Prediksi AI           Status\n",
              "0   AA4795BE.jpg      AA4795BE   GAGALCROP  FN (Gagal Crop)\n",
              "1   AB4622FO.jpg      AB4622FO    OZNB42F9  FP (Salah Baca)\n",
              "2   AB4848DH.jpg      AB4848DH    AB4848DH       TP (Benar)\n",
              "3   AB6628YJ.jpg      AB6628YJ    A86628Y0  FP (Salah Baca)\n",
              "4   AD2801BV.jpg      AD2801BV    AD2801BV       TP (Benar)\n",
              "5   BH2618MA.jpg      BH2618MA   GAGALCROP  FN (Gagal Crop)\n",
              "6    H2148BL.jpg       H2148BL   GAGALCROP  FN (Gagal Crop)\n",
              "7    H2462FK.jpg       H2462FK     H2462FK       TP (Benar)\n",
              "8    H2474VB.jpg       H2474VB     H2474VB       TP (Benar)\n",
              "9    H2575AK.jpg       H2575AK     H2575AK       TP (Benar)\n",
              "10   H2736SV.jpg       H2736SV     H2736SV       TP (Benar)\n",
              "11   H2964BK.jpg       H2964BK     H2964BK       TP (Benar)\n",
              "12   H3141NB.jpg       H3141NB   GAGALCROP  FN (Gagal Crop)\n",
              "13   H3367YB.jpg       H3367YB     H3367YB       TP (Benar)\n",
              "14   H3407EK.jpg       H3407EK     H3407EK       TP (Benar)\n",
              "15   H3783CI.jpg       H3783CI   GAGALCROP  FN (Gagal Crop)\n",
              "16   H3828HB.jpg       H3828HB     H3828HB       TP (Benar)\n",
              "17   H3882HK.jpg       H3882HK     H3882HK       TP (Benar)\n",
              "18   H3944GK.jpg       H3944GK     H3944GK       TP (Benar)\n",
              "19   H4264RK.jpg       H4264RK     H4264RK       TP (Benar)\n",
              "20   H4566VF.jpg       H4566VF     H4566VF       TP (Benar)\n",
              "21   H4635EV.jpg       H4635EV     H4635EV       TP (Benar)\n",
              "22   H5067FK.jpg       H5067FK     H5067FK       TP (Benar)\n",
              "23   H5279GK.jpg       H5279GK     H5279GK       TP (Benar)\n",
              "24   H5293LK.jpg       H5293LK     H5293LK       TP (Benar)\n",
              "25   H5396FK.jpg       H5396FK     H5396FK       TP (Benar)\n",
              "26   H56710L.jpg       H56710L     H567M80  FP (Salah Baca)\n",
              "27   H57200C.jpg       H57200C     H272O8C  FP (Salah Baca)\n",
              "28   H5735VB.jpg       H5735VB     H5735VB       TP (Benar)\n",
              "29   H5745FK.jpg       H5745FK     H5745FK       TP (Benar)\n",
              "30   H5953NK.jpg       H5953NK     H5953NK       TP (Benar)\n",
              "31   H62180B.jpg       H62180B     H62180B       TP (Benar)\n",
              "32   H6249NB.jpg       H6249NB     H6249NB       TP (Benar)\n",
              "33  H6426ALC.jpg      H6426ALC    H6426ALC       TP (Benar)\n",
              "34   H6496GK.jpg       H6496GK     H6496GK       TP (Benar)\n",
              "35   H6524AK.jpg       H6524AK     H6524AK       TP (Benar)\n",
              "36   H6629NB.jpg       H6629NB     H6629NB       TP (Benar)\n",
              "37   H6648KK.jpg       H6648KK     H6648KK       TP (Benar)\n",
              "38   H6726MK.jpg       H6726MK     H6726MK       TP (Benar)\n",
              "39   H6792DK.jpg       H6792DK     H6792DK       TP (Benar)\n",
              "40   H68140C.jpg       H68140C     H68N4U6  FP (Salah Baca)\n",
              "41   H6823DK.jpg       H6823DK     H6823DK       TP (Benar)\n",
              "42   H6832CV.jpg       H6832CV     H6832CV       TP (Benar)\n",
              "43   H6860ZB.jpg       H6860ZB     H6860ZB       TP (Benar)\n",
              "44   H6871BC.jpg       H6871BC   GAGALCROP  FN (Gagal Crop)\n",
              "45   K2344JU.jpg       K2344JU           R  FP (Salah Baca)\n",
              "46   K2771KZ.jpg       K2771KZ     K277EKZ  FP (Salah Baca)\n",
              "47  K3934AUC.jpg      K3934AUC    K3934AUC       TP (Benar)\n",
              "48  KH3227SH.jpg      KH3227SH    KH3227SH       TP (Benar)\n",
              "49  S4073JB0.jpg      S4073JB0    S4073JB0       TP (Benar)"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43a01bea-7412-4c76-8913-f02e3ebef4aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nama File</th>\n",
              "      <th>Kunci Jawaban</th>\n",
              "      <th>Prediksi AI</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AA4795BE.jpg</td>\n",
              "      <td>AA4795BE</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AB4622FO.jpg</td>\n",
              "      <td>AB4622FO</td>\n",
              "      <td>OZNB42F9</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AB4848DH.jpg</td>\n",
              "      <td>AB4848DH</td>\n",
              "      <td>AB4848DH</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AB6628YJ.jpg</td>\n",
              "      <td>AB6628YJ</td>\n",
              "      <td>A86628Y0</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AD2801BV.jpg</td>\n",
              "      <td>AD2801BV</td>\n",
              "      <td>AD2801BV</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BH2618MA.jpg</td>\n",
              "      <td>BH2618MA</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>H2148BL.jpg</td>\n",
              "      <td>H2148BL</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>H2462FK.jpg</td>\n",
              "      <td>H2462FK</td>\n",
              "      <td>H2462FK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>H2474VB.jpg</td>\n",
              "      <td>H2474VB</td>\n",
              "      <td>H2474VB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>H2575AK.jpg</td>\n",
              "      <td>H2575AK</td>\n",
              "      <td>H2575AK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>H2736SV.jpg</td>\n",
              "      <td>H2736SV</td>\n",
              "      <td>H2736SV</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>H2964BK.jpg</td>\n",
              "      <td>H2964BK</td>\n",
              "      <td>H2964BK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>H3141NB.jpg</td>\n",
              "      <td>H3141NB</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>H3367YB.jpg</td>\n",
              "      <td>H3367YB</td>\n",
              "      <td>H3367YB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>H3407EK.jpg</td>\n",
              "      <td>H3407EK</td>\n",
              "      <td>H3407EK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>H3783CI.jpg</td>\n",
              "      <td>H3783CI</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>H3828HB.jpg</td>\n",
              "      <td>H3828HB</td>\n",
              "      <td>H3828HB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>H3882HK.jpg</td>\n",
              "      <td>H3882HK</td>\n",
              "      <td>H3882HK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>H3944GK.jpg</td>\n",
              "      <td>H3944GK</td>\n",
              "      <td>H3944GK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>H4264RK.jpg</td>\n",
              "      <td>H4264RK</td>\n",
              "      <td>H4264RK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>H4566VF.jpg</td>\n",
              "      <td>H4566VF</td>\n",
              "      <td>H4566VF</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>H4635EV.jpg</td>\n",
              "      <td>H4635EV</td>\n",
              "      <td>H4635EV</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>H5067FK.jpg</td>\n",
              "      <td>H5067FK</td>\n",
              "      <td>H5067FK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>H5279GK.jpg</td>\n",
              "      <td>H5279GK</td>\n",
              "      <td>H5279GK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>H5293LK.jpg</td>\n",
              "      <td>H5293LK</td>\n",
              "      <td>H5293LK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>H5396FK.jpg</td>\n",
              "      <td>H5396FK</td>\n",
              "      <td>H5396FK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>H56710L.jpg</td>\n",
              "      <td>H56710L</td>\n",
              "      <td>H567M80</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>H57200C.jpg</td>\n",
              "      <td>H57200C</td>\n",
              "      <td>H272O8C</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>H5735VB.jpg</td>\n",
              "      <td>H5735VB</td>\n",
              "      <td>H5735VB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>H5745FK.jpg</td>\n",
              "      <td>H5745FK</td>\n",
              "      <td>H5745FK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>H5953NK.jpg</td>\n",
              "      <td>H5953NK</td>\n",
              "      <td>H5953NK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>H62180B.jpg</td>\n",
              "      <td>H62180B</td>\n",
              "      <td>H62180B</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>H6249NB.jpg</td>\n",
              "      <td>H6249NB</td>\n",
              "      <td>H6249NB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>H6426ALC.jpg</td>\n",
              "      <td>H6426ALC</td>\n",
              "      <td>H6426ALC</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>H6496GK.jpg</td>\n",
              "      <td>H6496GK</td>\n",
              "      <td>H6496GK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>H6524AK.jpg</td>\n",
              "      <td>H6524AK</td>\n",
              "      <td>H6524AK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>H6629NB.jpg</td>\n",
              "      <td>H6629NB</td>\n",
              "      <td>H6629NB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>H6648KK.jpg</td>\n",
              "      <td>H6648KK</td>\n",
              "      <td>H6648KK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>H6726MK.jpg</td>\n",
              "      <td>H6726MK</td>\n",
              "      <td>H6726MK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>H6792DK.jpg</td>\n",
              "      <td>H6792DK</td>\n",
              "      <td>H6792DK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>H68140C.jpg</td>\n",
              "      <td>H68140C</td>\n",
              "      <td>H68N4U6</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>H6823DK.jpg</td>\n",
              "      <td>H6823DK</td>\n",
              "      <td>H6823DK</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>H6832CV.jpg</td>\n",
              "      <td>H6832CV</td>\n",
              "      <td>H6832CV</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>H6860ZB.jpg</td>\n",
              "      <td>H6860ZB</td>\n",
              "      <td>H6860ZB</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>H6871BC.jpg</td>\n",
              "      <td>H6871BC</td>\n",
              "      <td>GAGALCROP</td>\n",
              "      <td>FN (Gagal Crop)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>K2344JU.jpg</td>\n",
              "      <td>K2344JU</td>\n",
              "      <td>R</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>K2771KZ.jpg</td>\n",
              "      <td>K2771KZ</td>\n",
              "      <td>K277EKZ</td>\n",
              "      <td>FP (Salah Baca)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>K3934AUC.jpg</td>\n",
              "      <td>K3934AUC</td>\n",
              "      <td>K3934AUC</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>KH3227SH.jpg</td>\n",
              "      <td>KH3227SH</td>\n",
              "      <td>KH3227SH</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>S4073JB0.jpg</td>\n",
              "      <td>S4073JB0</td>\n",
              "      <td>S4073JB0</td>\n",
              "      <td>TP (Benar)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43a01bea-7412-4c76-8913-f02e3ebef4aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43a01bea-7412-4c76-8913-f02e3ebef4aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43a01bea-7412-4c76-8913-f02e3ebef4aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-750c5213-1124-45e8-93d6-91e84b795cf6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-750c5213-1124-45e8-93d6-91e84b795cf6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-750c5213-1124-45e8-93d6-91e84b795cf6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ae234754-d6d2-4c17-a3b6-5c3a7f964c6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae234754-d6d2-4c17-a3b6-5c3a7f964c6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Nama File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"H3367YB.jpg\",\n          \"H6792DK.jpg\",\n          \"H5953NK.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kunci Jawaban\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"H3367YB\",\n          \"H6792DK\",\n          \"H5953NK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prediksi AI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"H6860ZB\",\n          \"H5745FK\",\n          \"H5953NK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FN (Gagal Crop)\",\n          \"FP (Salah Baca)\",\n          \"TP (Benar)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸ“ˆ LAPORAN EVALUASI MODEL (F1-SCORE)\n",
            "==================================================\n",
            "Total Data      : 50\n",
            "âœ… True Positive : 37 (Benar)\n",
            "âš ï¸ False Positive: 7 (Salah Baca)\n",
            "âŒ False Negative: 6 (Gagal Deteksi)\n",
            "------------------------------\n",
            "ğŸ¯ AKURASI   : 74.00%\n",
            "ğŸ¯ PRESISI   : 84.09%\n",
            "ğŸ¯ RECALL    : 86.05%\n",
            "ğŸ† F1-SCORE  : 85.06%\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}